{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# TUTORIAL FROM https://colab.research.google.com/drive/17Fql7pyK3xsO8KmZorvb1tBoPomidCPB#scrollTo=hKDhJGQVqb3Y \n",
        "# enables music21 to render images of musical notes\n",
        "print('installing lilypond...')\n",
        "!apt-get install lilypond > /dev/null\n",
        "# converts midi files to wav files into order to play them\n",
        "print('installing fluidsynth...')\n",
        "!apt-get install fluidsynth > /dev/null\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
        "print('done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTzpfL--jf8f",
        "outputId": "e853c8b0-08d8-4fb6-a4ec-67baef654b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installing lilypond...\n",
            "Extracting templates from packages: 100%\n",
            "installing fluidsynth...\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show(music):\n",
        "  display(Image(str(music.write('lily.png'))))\n",
        "\n",
        "def play(music):\n",
        "  filename = music.write('mid')\n",
        "  !fluidsynth -ni font.sf2 $filename -F $filename\\.wav -r 16000 > /dev/null\n",
        "  display(Audio(filename + '.wav'))"
      ],
      "metadata": {
        "id": "j_NTOPakj-Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hqo3ZVoqcGJh",
        "outputId": "c086601b-fd03-403f-a19e-4773f3e308ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import music21 \n",
        "from music21 import *\n",
        "# music21.configure.run()\n",
        "\n",
        "import glob\n",
        "import pickle\n",
        "from IPython.display import Image, Audio # to show scores and play audios\n",
        "import os # to join paths (folders and file names)\n",
        "import csv\n",
        "import copy\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this should enable MuseScore to open up when needed and show scores, but it does not work\n",
        "'''\n",
        "us = music21.environment.UserSettings()\n",
        "us['musicxmlPath'] = '/Applications/MuseScore 3.app/Contents/MacOS/mscore'\n",
        "us['musescoreDirectPNGPath'] = '/Applications/MuseScore 3.app/Contents/MacOS/mscore'\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_OJJk-Syodxk",
        "outputId": "80d279b5-a00b-4226-ecf2-1879e53e3a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nus = music21.environment.UserSettings()\\nus['musicxmlPath'] = '/Applications/MuseScore 3.app/Contents/MacOS/mscore'\\nus['musescoreDirectPNGPath'] = '/Applications/MuseScore 3.app/Contents/MacOS/mscore'\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GLOBAL PATHS\n",
        "jingJuScoresDataset_XMLFolder = '/content/gdrive/MyDrive/Colab Notebooks/Audio and Music Processing Lab/Computational Musicology/Assignment/Jingju Scores Dataset/MusicXML'\n",
        "linesCSV_FilePath = '/content/gdrive/MyDrive/Colab Notebooks/Audio and Music Processing Lab/Computational Musicology/Assignment/Jingju Scores Dataset/MuseScore/lines_data.csv'\n",
        "linesSimilarityCSV_FilePath = '/content/gdrive/MyDrive/Colab Notebooks/Audio and Music Processing Lab/Computational Musicology/Assignment/lines_similarity.csv'\n",
        "pickleFilesFolder = '/content/gdrive/MyDrive/Colab Notebooks/Audio and Music Processing Lab/Computational Musicology/Assignment'"
      ],
      "metadata": {
        "id": "Y1ripVyTdNDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def getListOfHeterophonyIntervals_Between2Parts(voicePart, accompPart):\n",
        "  # This function takes 2 parts (voice and accompaniment part) and computes the \n",
        "  # heterohpny intervals (relative to the voice part, excluding unisons)\n",
        "  # between them. Returns a list of dictionaries\n",
        "  # (one dictionary for each heterophony interval) with;\n",
        "  # {'Interval_class':, 'Interval_duration':, 'Voice_part_lyrics':})\n",
        "\n",
        "  listOfIntervals = list()\n",
        "  soundingNotes = music21.stream.Stream()\n",
        "  for voiceNote in voicePart.notes:\n",
        "    newSoundingNotes = accompPart.getElementsByOffset(voiceNote.offset, offsetEnd=voiceNote.offset+voiceNote.quarterLength, includeElementsThatEndAtStart=False, mustFinishInSpan=False, mustBeginInSpan=False, includeEndBoundary=False).stream()\n",
        "    for accompNote in newSoundingNotes.notes:      \n",
        "      interval = music21.interval.Interval(noteStart = voiceNote, noteEnd = accompNote)\n",
        "      if interval.semitones != 0: # if interval is not a unison\n",
        "        if accompNote.offset < voiceNote.offset: # if accompNote starts earlier than voiceNote\n",
        "          interval.quarterLength = (accompNote.offset + accompNote.quarterLength) - voiceNote.offset\n",
        "          interval.offset = voiceNote.offset\n",
        "        else:\n",
        "          interval.quarterLength = accompNote.quarterLength\n",
        "          interval.offset = accompNote.offset\n",
        "        # if accompaniment note ends after voice note's end \n",
        "        if (accompNote.offset + accompNote.quarterLength) > (voiceNote.offset + voiceNote.quarterLength):\n",
        "          interval.quarterLength = ((accompNote.offset + accompNote.quarterLength) - (voiceNote.offset + voiceNote.quarterLength)) - accompNote.offset \n",
        "\n",
        "        duration = music21.duration.Duration()\n",
        "        duration.quarterLength = interval.quarterLength\n",
        "\n",
        "        if voiceNote.hasLyrics:\n",
        "          listOfIntervals.append({'Measure_number': voiceNote.measureNumber, 'Interval_class': interval.directedNiceName, 'Interval_duration': interval.quarterLength, 'Voice_part_lyrics': voiceNote.lyric})\n",
        "        else:\n",
        "          listOfIntervals.append({'Measure_number': voiceNote.measureNumber, 'Interval_class': interval.directedNiceName, 'Interval_duration': interval.quarterLength})\n",
        "\n",
        "  return listOfIntervals\n",
        "'''"
      ],
      "metadata": {
        "id": "xwLidYBikSTz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "a2d880ad-e1c7-457c-bac2-40f67265c33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef getListOfHeterophonyIntervals_Between2Parts(voicePart, accompPart):\\n  # This function takes 2 parts (voice and accompaniment part) and computes the \\n  # heterohpny intervals (relative to the voice part, excluding unisons)\\n  # between them. Returns a list of dictionaries\\n  # (one dictionary for each heterophony interval) with;\\n  # {'Interval_class':, 'Interval_duration':, 'Voice_part_lyrics':})\\n\\n  listOfIntervals = list()\\n  soundingNotes = music21.stream.Stream()\\n  for voiceNote in voicePart.notes:\\n    newSoundingNotes = accompPart.getElementsByOffset(voiceNote.offset, offsetEnd=voiceNote.offset+voiceNote.quarterLength, includeElementsThatEndAtStart=False, mustFinishInSpan=False, mustBeginInSpan=False, includeEndBoundary=False).stream()\\n    for accompNote in newSoundingNotes.notes:      \\n      interval = music21.interval.Interval(noteStart = voiceNote, noteEnd = accompNote)\\n      if interval.semitones != 0: # if interval is not a unison\\n        if accompNote.offset < voiceNote.offset: # if accompNote starts earlier than voiceNote\\n          interval.quarterLength = (accompNote.offset + accompNote.quarterLength) - voiceNote.offset\\n          interval.offset = voiceNote.offset\\n        else:\\n          interval.quarterLength = accompNote.quarterLength\\n          interval.offset = accompNote.offset\\n        # if accompaniment note ends after voice note's end \\n        if (accompNote.offset + accompNote.quarterLength) > (voiceNote.offset + voiceNote.quarterLength):\\n          interval.quarterLength = ((accompNote.offset + accompNote.quarterLength) - (voiceNote.offset + voiceNote.quarterLength)) - accompNote.offset \\n\\n        duration = music21.duration.Duration()\\n        duration.quarterLength = interval.quarterLength\\n\\n        if voiceNote.hasLyrics:\\n          listOfIntervals.append({'Measure_number': voiceNote.measureNumber, 'Interval_class': interval.directedNiceName, 'Interval_duration': interval.quarterLength, 'Voice_part_lyrics': voiceNote.lyric})\\n        else:\\n          listOfIntervals.append({'Measure_number': voiceNote.measureNumber, 'Interval_class': interval.directedNiceName, 'Interval_duration': interval.quarterLength})\\n\\n  return listOfIntervals\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def filter_FullHeterophonyIntervalsList_IntoLineIntervalsDict(fullHeterophonyIntervalsList, lineDuration, startMeasure, endMeasure):\n",
        "  lineIntervalsList = dict()\n",
        "  for intervalDict in fullHeterophonyIntervalsList:\n",
        "    if intervalDict['Measure_number'] >= startMeasure and intervalDict['Measure_number'] <= endMeasure:\n",
        "      if intervalDict['Interval_class'] in lineIntervalsList:\n",
        "        lineIntervalsList[intervalDict['Interval_class']] = lineIntervalsList[intervalDict['Interval_class']] + intervalDict['Interval_duration']\n",
        "      else:\n",
        "        lineIntervalsList[intervalDict['Interval_class']] = intervalDict['Interval_duration']\n",
        "      lineIntervalsList[intervalDict['Interval_class']] = round(lineIntervalsList[intervalDict['Interval_class']] / lineDuration, 3)\n",
        "    # print(lineIntervalsList)\n",
        "  return lineIntervalsList\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "xY7F66m22KeE",
        "outputId": "ad2ddf03-ba01-4926-fee4-17d6460f784b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef filter_FullHeterophonyIntervalsList_IntoLineIntervalsDict(fullHeterophonyIntervalsList, lineDuration, startMeasure, endMeasure):\\n  lineIntervalsList = dict()\\n  for intervalDict in fullHeterophonyIntervalsList:\\n    if intervalDict['Measure_number'] >= startMeasure and intervalDict['Measure_number'] <= endMeasure:\\n      if intervalDict['Interval_class'] in lineIntervalsList:\\n        lineIntervalsList[intervalDict['Interval_class']] = lineIntervalsList[intervalDict['Interval_class']] + intervalDict['Interval_duration']\\n      else:\\n        lineIntervalsList[intervalDict['Interval_class']] = intervalDict['Interval_duration']\\n      lineIntervalsList[intervalDict['Interval_class']] = round(lineIntervalsList[intervalDict['Interval_class']] / lineDuration, 3)\\n    # print(lineIntervalsList)\\n  return lineIntervalsList\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "listOfUniqueIntervals = ['Descending Minor Third', 'Ascending Perfect Octave', 'Descending Minor Second', 'Ascending Perfect Fifth', 'Ascending Minor Seventh', 'Descending Major Second', 'Descending Perfect Eleventh', 'Ascending Minor Second', 'Descending Perfect Octave', 'Ascending Perfect Fourth', 'Descending Perfect Twelfth', 'Descending Perfect Fifth', 'Line_number:', 'Descending Minor Tenth', 'Descending Minor Ninth', 'Descending Major Seventh', 'Descending Major Ninth', 'Ascending Major Second', 'Ascending Minor Third', 'Descending Major Tenth', 'Descending Minor Seventh', 'Ascending Major Sixth', 'Descending Minor Sixth', 'Descending Major Third', 'Ascending Major Third', 'Descending Major Sixth', 'Ascending Minor Sixth', 'Descending Perfect Fourth']\n",
        "print(listOfUniqueIntervals)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "OPe0hIsdVs_Y",
        "outputId": "f8734480-8180-4095-c950-b56c38273c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nlistOfUniqueIntervals = ['Descending Minor Third', 'Ascending Perfect Octave', 'Descending Minor Second', 'Ascending Perfect Fifth', 'Ascending Minor Seventh', 'Descending Major Second', 'Descending Perfect Eleventh', 'Ascending Minor Second', 'Descending Perfect Octave', 'Ascending Perfect Fourth', 'Descending Perfect Twelfth', 'Descending Perfect Fifth', 'Line_number:', 'Descending Minor Tenth', 'Descending Minor Ninth', 'Descending Major Seventh', 'Descending Major Ninth', 'Ascending Major Second', 'Ascending Minor Third', 'Descending Major Tenth', 'Descending Minor Seventh', 'Ascending Major Sixth', 'Descending Minor Sixth', 'Descending Major Third', 'Ascending Major Third', 'Descending Major Sixth', 'Ascending Minor Sixth', 'Descending Perfect Fourth']\\nprint(listOfUniqueIntervals)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateSimilarity(voice_flat, accom_flat):\n",
        "  \"\"\"\n",
        "  Given two flattened Music21 score parts, it will calculate what percentage of the voice's total\n",
        "  performance has rhythmic or melodic overlap with the accompanying part. Pitch is defined as having\n",
        "  the exact same pitch (same octave), and rhythm must be the same start and end time. \n",
        "  It returns these two values as a percentage, i.e. if the melody plays 4 quarter-notes, and the \n",
        "  accompaniament plays one quarter note of the same pitch, it will be a ratio of 25%.\n",
        "\n",
        "  Inputs:\n",
        "  voice_flat (flattened music21 part), the 'melodic' line\n",
        "  accom_flat (flattened music21 part), the 'accompaniament' line\n",
        "  \n",
        "  Returns:\n",
        "  Pitch Ratio (float)\n",
        "  Rhythm Ratio (float)\n",
        "  \"\"\"\n",
        "  total_voice_notes = 0\n",
        "  total_voice_rhythm = 0.0\n",
        "  p_sim = 0.0\n",
        "  r_sim = 0.0\n",
        "  \n",
        "  for voice_note in voice_flat.notes:\n",
        "    #remove grace notes\n",
        "    if voice_note.duration.quarterLength > 0.0: \n",
        "      total_voice_notes += 1\n",
        "      total_voice_rhythm += voice_note.duration.quarterLength\n",
        "\n",
        "      # define the range of the melodic note, and get all accompaniament notes in that range\n",
        "      start_range = voice_note.offset\n",
        "      end_range = voice_note.offset + voice_note.duration.quarterLength\n",
        "      accompany_filtered = copy.deepcopy(accom_flat)\n",
        "\n",
        "      notes_in_range = [n for n in accompany_filtered.getElementsByOffset\n",
        "                        (start_range, end_range, \n",
        "                        includeEndBoundary=False,\n",
        "                        mustBeginInSpan=True) \n",
        "      if isinstance(n, note.Note)]\n",
        "\n",
        "\n",
        "      if not notes_in_range:\n",
        "        pass\n",
        "\n",
        "      else:\n",
        "        \n",
        "        # Rhythm is only considered identical if there is a single note with the same start/end offsets as voice note\n",
        "        if len(notes_in_range) == 1:\n",
        "          single_note = notes_in_range[0]\n",
        "          if single_note.duration.quarterLength == voice_note.duration.quarterLength:\n",
        "            r_sim += voice_note.duration.quarterLength\n",
        "\n",
        "        # For each overlapping accom note, we check if it is the same as voice note. If so, we add its duration\n",
        "        # and calculate the total as a ratio to the duration of the voice note\n",
        "        for one_note in notes_in_range:\n",
        "          if one_note.pitch.nameWithOctave == voice_note.pitch.nameWithOctave:\n",
        "            p_sim += min(one_note.duration.quarterLength, voice_note.duration.quarterLength)\n",
        "\n",
        "  if p_sim > 0.0:\n",
        "    pitch_ratio = round((p_sim / total_voice_rhythm * 100), 2)\n",
        "  else:\n",
        "    pitch_ratio = 0.0\n",
        "  \n",
        "  if r_sim > 0.0:\n",
        "    rhythm_ratio = round((r_sim / total_voice_rhythm * 100), 2)\n",
        "  else:\n",
        "    rhythm_ratio = 0.0\n",
        "\n",
        "  return pitch_ratio, rhythm_ratio"
      ],
      "metadata": {
        "id": "4M9Gl_hVg6xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def getSimilarityBetweenOffsets_FromXMLFile(xmlFile, startOffset, endOffset):\n",
        "  # print(f'Called getSimilarityBetweenOffsets_FromXMLFile, startOffset ; {startOffset} , endOffset ; {endOffset}')\n",
        "  \n",
        "  s = converter.parse(xmlFile)\n",
        "  full_song = s.parts.stream()\n",
        "\n",
        "  thisFile_Dict = dict()\n",
        "\n",
        "  wasAccompPartFound = False\n",
        "  wasVoicePartAFound = False\n",
        "\n",
        "  accompPartNum = 0\n",
        "  voicePartANum = 0\n",
        "\n",
        "  parts = copy.deepcopy(full_song)\n",
        "\n",
        "  # Part docs\n",
        "  # http://web.mit.edu/music21/doc/moduleReference/moduleStreamBase.html#module-music21.stream.base\n",
        "  count = 0\n",
        "  for part in parts:\n",
        "    if len(part.lyrics()) == 0 and wasAccompPartFound == False:\n",
        "      accom_flattened = part.flat.notes.stream()\n",
        "      accompPart = accom_flattened.getElementsByOffset(startOffset, endOffset)\n",
        "      wasAccompPartFound = True\n",
        "      accompPartNum = count\n",
        "    elif len(part.lyrics()) > 0 and wasVoicePartAFound == False:\n",
        "      voice_flattened = part.flat.notes.stream()\n",
        "      voicePartA = voice_flattened.getElementsByOffset(startOffset, endOffset)\n",
        "      wasVoicePartAFound = True\n",
        "      voicePartANum = count\n",
        "    else:\n",
        "      break\n",
        "    count += 1\n",
        "\n",
        "  if wasVoicePartAFound and wasAccompPartFound:\n",
        "    pitch_similarity, rhythm_similarity = calculateSimilarity(voicePartA, accompPart)\n",
        "    thisFile_Dict = {'Pitch_similarity': pitch_similarity, 'Rhythm_similarity': rhythm_similarity}\n",
        "\n",
        "  # print(f'Calculated similarity ; {thisFile_Dict}')\n",
        "  return thisFile_Dict"
      ],
      "metadata": {
        "id": "haNfOXpn_Uz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(linesCSV_FilePath, 'r') as lineCSV_File:\n",
        "  with open(linesSimilarityCSV_FilePath, \"w\") as linesSimilarityCSV_File:\n",
        "    fieldnames = ['File name', 'Role type', 'Shengqiang', 'Banshi', 'Couplet line', 'Lyrics line', 'Line_number', 'Start', 'End', 'Pitch_similarity', 'Rhythm_similarity']\n",
        "    csvWriter = csv.DictWriter(linesSimilarityCSV_File, fieldnames=fieldnames)\n",
        "    csvWriter.writeheader()\n",
        "    reader = csv.DictReader(lineCSV_File)\n",
        "    lastFileNameAnalyzed = str()\n",
        "    lineCount = 0\n",
        "    for row in reader:\n",
        "        if row['File name'] != lastFileNameAnalyzed:\n",
        "          lastFileNameAnalyzed = row['File name']\n",
        "          lineCount = 0\n",
        "        if os.path.isfile(os.path.join(jingJuScoresDataset_XMLFolder, row['File name'])):\n",
        "          if '/' not in row['Start'] and '/' not in row['End'] and '.' not in row['Start'] and '.' not in row['End']:\n",
        "            startOffset = row['Start']\n",
        "            startOffset = startOffset.replace(' ', '')\n",
        "            startOffset = startOffset.replace(',', '.')\n",
        "            endOffset = row['End']\n",
        "            endOffset = endOffset.replace(' ', '')\n",
        "            endOffset = endOffset.replace(',', '.')\n",
        "            if startOffset != '' and endOffset != '':\n",
        "              rowDict = {'File name': row['File name'], 'Role type': row['Role type'], 'Shengqiang': row['Shengqiang'], 'Banshi': row['Banshi'], 'Couplet line': row['Couplet line'], 'Lyrics line': row['Lyrics line'], 'Line_number': lineCount+1, 'Start': float(startOffset), 'End': float(endOffset)}\n",
        "              rowDict.update(getSimilarityBetweenOffsets_FromXMLFile(os.path.join(jingJuScoresDataset_XMLFolder, rowDict['File name']), rowDict['Start'], rowDict['End']))\n",
        "              csvWriter.writerow(rowDict)\n",
        "              lineCount += 1"
      ],
      "metadata": {
        "id": "VNryw2bhKeaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}